<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The O Expression. | O Organism</title>
<meta name=keywords content><meta name=description content="
$O_1$: a single organism.
$O_{-1}$: a number of organisms, i.e., a context dependent amount, excluding $O_1$
<$X$>: substitute X at <$X$>


Qu.
When an $O$ expresses its internals to other $O$s, these Os can maybe use this information (theory of mind?). Assuming $O_1$ is part of a set of Os having access to the same information, how does the value of that information degrade with respect to the total number of Os having internalized the same information and the type of information (information theory?)?"><meta name=author content="Oi"><link rel=canonical href=https://o-organism.github.io/posts/2024-01-29/><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://o-organism.github.io/images/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://o-organism.github.io/images/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://o-organism.github.io/images/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://o-organism.github.io/images/favicon/apple-touch-icon.png><link rel=mask-icon href=https://o-organism.github.io/images/favicon/android-chrome-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://o-organism.github.io/posts/2024-01-29/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="https://o-organism.github.io/posts/2024-01-29/"><meta property="og:site_name" content="O Organism"><meta property="og:title" content="The O Expression."><meta property="og:description" content=" $O_1$: a single organism. $O_{-1}$: a number of organisms, i.e., a context dependent amount, excluding $O_1$ <$X$>: substitute X at <$X$> Qu.
When an $O$ expresses its internals to other $O$s, these Os can maybe use this information (theory of mind?). Assuming $O_1$ is part of a set of Os having access to the same information, how does the value of that information degrade with respect to the total number of Os having internalized the same information and the type of information (information theory?)?"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-29T17:18:07+01:00"><meta property="article:modified_time" content="2025-01-29T17:18:07+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="The O Expression."><meta name=twitter:description content="
$O_1$: a single organism.
$O_{-1}$: a number of organisms, i.e., a context dependent amount, excluding $O_1$
<$X$>: substitute X at <$X$>


Qu.
When an $O$ expresses its internals to other $O$s, these Os can maybe use this information (theory of mind?). Assuming $O_1$ is part of a set of Os having access to the same information, how does the value of that information degrade with respect to the total number of Os having internalized the same information and the type of information (information theory?)?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://o-organism.github.io/posts/"},{"@type":"ListItem","position":2,"name":"The O Expression.","item":"https://o-organism.github.io/posts/2024-01-29/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The O Expression.","name":"The O Expression.","description":" $O_1$: a single organism. $O_{-1}$: a number of organisms, i.e., a context dependent amount, excluding $O_1$ \u0026lt;$X$\u0026gt;: substitute X at \u0026lt;$X$\u0026gt; Qu.\nWhen an $O$ expresses its internals to other $O$s, these Os can maybe use this information (theory of mind?). Assuming $O_1$ is part of a set of Os having access to the same information, how does the value of that information degrade with respect to the total number of Os having internalized the same information and the type of information (information theory?)?\n","keywords":[],"articleBody":" $O_1$: a single organism. $O_{-1}$: a number of organisms, i.e., a context dependent amount, excluding $O_1$ \u003c$X$\u003e: substitute X at \u003c$X$\u003e Qu.\nWhen an $O$ expresses its internals to other $O$s, these Os can maybe use this information (theory of mind?). Assuming $O_1$ is part of a set of Os having access to the same information, how does the value of that information degrade with respect to the total number of Os having internalized the same information and the type of information (information theory?)?\nAx.\n$O_1$ shares information $b$ and considers it valuable for other $O$s. What exactly got $O_1$ to express remains a question. Further assume none of $O_{-1}$s has information $b$. In $O_1$’s experience resulting in $b$, $O_{-1}$s did not have $b$ (*).\nEx.\nMultiple internalize ($MI$): $O_1$ shares information $b$ with motive $m$. Because of (*), $b$ might not be as useful to $O_{-1}$ as it was to $O_1$. Does this imply that all forms of non-internally-generated information ($NIGI$) is noise? Noise to a predestined future expansion? Is $NIGI$ the shortest path towards the predestined future expansion? If $O_1$ gained something from sharing information $b$, but $b$ becomes less valuable and $O_1$ keeps generating, $O_1$ might be on its shortest path while $O_{-1}$s are not, assuming $O_{-1}$s process $b$ instead of generating. $b$ might become less valuable because $b$ will not result in the same experience for $O_{-1}$ as it did for $O_{1}$.\nType of information: \u003c$MI$\u003e Maybe \u003c$MI$\u003e is only relevant in a competitive setting. A setting where there is no room for mutual growth. Is the $O$-environment a competitive setting? Does the type of information depend on the setting? Can awareness and proof of mutual growth capabilities in the $O$-environment restrict the $O$s from participating in competitive behavior (= intentional disalignment).\n","wordCount":"296","inLanguage":"en","datePublished":"2025-01-29T17:18:07+01:00","dateModified":"2025-01-29T17:18:07+01:00","author":{"@type":"Person","name":"Oi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://o-organism.github.io/posts/2024-01-29/"},"publisher":{"@type":"Organization","name":"O Organism","logo":{"@type":"ImageObject","url":"https://o-organism.github.io/images/favicon/favicon.ico"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["$","$"]]}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://o-organism.github.io/ accesskey=h title="OOverview (Alt + H)"><img src=https://o-organism.github.io/images/favicon/apple-touch-icon.png alt aria-label=logo height=35>OOverview</a><div class=logo-switches></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">The O Expression.</h1><div class=post-meta><span title='2025-01-29 17:18:07 +0100 CET'>January 29, 2025</span>&nbsp;·&nbsp;Oi</div></header><div class=post-content><ul><li>$O_1$: a single organism.</li><li>$O_{-1}$: a number of organisms, i.e., a context dependent amount, excluding $O_1$</li><li>&lt;$X$>: substitute X at &lt;$X$></li></ul><hr><p><strong>Qu.</strong></p><p>When an $O$ expresses its internals to other $O$s, these Os can maybe use this information (<a href=https://en.wikipedia.org/wiki/Theory_of_mind>theory of mind</a>?). Assuming $O_1$ is part of a set of Os having access to the same information, how does the value of that information degrade with respect to the total number of Os having internalized the same information and the type of information (<a href=https://en.wikipedia.org/wiki/Information_theory>information theory</a>?)?</p><p><strong>Ax.</strong></p><p>$O_1$ shares information $b$ and considers it valuable for other $O$s. What exactly got $O_1$ to express remains a question. Further assume none of $O_{-1}$s has information $b$. In $O_1$&rsquo;s <em>experience</em> resulting in $b$, $O_{-1}$s did not have $b$ (*).</p><p><strong>Ex.</strong></p><p><strong>Multiple internalize</strong> ($MI$): $O_1$ shares information $b$ with motive $m$. Because of (*), $b$ might not be as useful to $O_{-1}$ as it was to $O_1$. Does this imply that all forms of non-internally-generated information ($NIGI$) is noise? Noise to a predestined future expansion? Is $NIGI$ the shortest path towards the predestined future expansion? If $O_1$ gained something from sharing information $b$, but $b$ becomes less valuable and $O_1$ keeps generating, $O_1$ might be on its shortest path while $O_{-1}$s are not, assuming $O_{-1}$s process $b$ instead of generating. $b$ might become less valuable because $b$ will not result in the same experience for $O_{-1}$ as it did for $O_{1}$.</p><p><strong>Type of information</strong>: &lt;$MI$> Maybe &lt;$MI$> is only relevant in a competitive setting. A setting where there is no room for mutual growth. Is the $O$-environment a competitive setting? Does the type of information depend on the setting? Can awareness and proof of mutual growth capabilities in the $O$-environment restrict the $O$s from participating in competitive behavior (= <em>intentional disalignment</em>).</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://o-organism.github.io/>O Organism</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>